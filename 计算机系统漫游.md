# 第一章 计算机系统漫游

## 1.1 信息就是位+上下文

系统中的所有信息--包括磁盘文件、内存中的程序、内存中存放的用户数据以及网络上传送的数据，都是由一串**比特**表示的。区分不同数据对象的唯一方法是读到这些数据对象时的上下文。

**C语言**是贝尔实验室的Dennis Richie于1969年~1973年间创建的。**美国国家标准学会**（American National Standards Institute, ANSI）在1989年颁布了ANSI C的标准，后来C语言的标准化成了**国际标准化组织**（International standards Origanization, ISO）的责任。

## 1.2 程序被其他程序翻译成不同的格式

对于源程序`hello.c`，GCC编译器将其翻译成一个可执行目标文件`hello`。这个翻译过程分为四个阶段完成，执行这四个阶段的程序（预处理器、编译器、汇编器和链接器）一起构成了编译系统。

<div align = center>
<img src = "https://img-blog.csdnimg.cn/2019100609340741.png" width = "80%">
<div align = left>
  
**GCC**是GNU(GND是GNU's not Unix的缩写）项目开发出来的众多有用工具之一。GNU项目是1984年由Richard Stallman发起的一个免税的慈善项目。该项目的目标非常宏大，就是开发出一个完整的类Unix的系统，其源代码能够不被限制地被修改和传播。

## 1.3 了解编译系统如何工作是大有益处的

**优化程序性能**、**理解链接时出现的错误**、**避免安全漏洞**

## 1.4 处理器读并解释存储在内存中的指令

### 1.4.1 系统的硬件组成

下面是一个典型系统的硬件组成：

<div align = center>
<img src = "https://img-blog.csdnimg.cn/20191006094714780.png" width = "80%">
<div align = left>
  
**1. 总线**

总线是贯穿整个系统的一组电子管道，它携带信息字节并负责在各个部件间传递。

通常总线被设计成传送字长的字节块，也就是字（word）。字中的字节数（即字长）是个基本的系统参数，各个系统中都不尽相同。

**2. IO设备**

IO设备是与系统与外部世界的联系通道。每个IO设备都通过一个控制器或适配器与IO总线相连。

**控制器**是IO设备本身或者系统的主印制电路板（主板）上的芯片组。

**适配器**是一块插在主板插槽上的卡。

**3. 主存**

**主存**是一个临时存储设备，在处理器执行程序时，用来存放程序和程序处理的数据。

从物理上来说，主存是由一组**动态随机存取存储器**（DRAM）芯片组成的。

从逻辑上来说，存储器是一个线性的字节数组，每个字节都有其唯一的地址，这些地址是从零开始的。

**4. 处理器**

**中央处理单元**（CPU），简称处理器，是解释或执行存储在主存中指令的引擎。

处理器的核心是一个大小为一个子的存储设备（或寄存器），称为程序计数器（PC）。在任何时刻，PC都执行主存中的某条机器语言指令。

**寄存器文件**是一个小的存储设备，由一些单个字长的存储器组成，每个存储器都有唯一的名字。

下面是一个简单的执行指令的例子：

- 加载：从主存复制一个字节或者一个子到寄存器，以覆盖寄存器原来的内容。
- 存储：从寄存器复制一个字节或者一个字到主存的某个位置，以覆盖这个位置上原来的内容。
- 操作：把两个寄存器的内容复制到ALU，ALU对这两个字做算数运算，并将结果存放到一个寄存器中，以覆盖该寄存器中原来的内容。
- 跳转：从指令本身中抽取一个字，并将这个字复制到程序计数器（PC）中，以覆盖PC中原来的值。

## 1.5 高速缓存至关重要

位于处理器芯片上的**L1高速缓存**的容量可以达到数万字节，访问速度几乎和访问寄存器文件一样快。

一个容量为数十万到数百万字节的更大的**L2高速缓存**通过一条特殊的总线连接到处理器。进程访问L2高速缓存的时间要比访问L1高速缓存的时间长5倍，但仍比访问主存的时间快5-10倍。

L1和L2高速缓存是用一种**静态随机访问存储器**（SRAM）的硬件技术实现的。

比较新的、处理能力更强大的系统甚至有三级高速缓存：L1、L2和L3。

系统可以获得一个很大的存储器，同时访问速度也很快，原因是利用了高速缓存的局部性原理，即程序具有访问局部区域里的数据和代码的趋势。通过让高速缓存里存放可能经常范文的数据，大部分的内存操作能在快速的高速缓存中完成。

<div align = center>
<img src = "https://img-blog.csdnimg.cn/20191006101726343.png" width = "80%">
<div align = left>

## 1.6 存储设备形成层次结构

每个计算机系统的存储设备都被组织成了一个**存储器层次结构**，如下图所示，在这个层次结构中，从上至下，设备的访问速度越来越慢、容量越来越大，并且没字节的造价也越来越便宜。

<div align = center>
<img src = "https://img-blog.csdnimg.cn/20191006102039188.png" width = "80%">
<div align = left>
  
存储器层次结构的主要思想是上一层的存储器作为第一层存储器的高速缓存，因此，寄存器文件就是L1的高速缓存，L1是L2的高速缓存，L2是L3的高速缓存，L3是主存的高速缓存，而主存又是磁盘的高速缓存，等等。

## 1.7 操作系统管理硬件

我们可以把**操作系统**看成是应用程序和硬件之间插入的一层软件。如下图所示，所有的应用程序对硬件的操作尝试都必须通过操作系统：

<div align = center>
<img src = "https://img-blog.csdnimg.cn/20191006103229378.png" width = "80%">
<div align = left>

**操作系统**有两个基本功能：（1）防止硬件被使用的应用程序滥用；（2）向应用程序提供简单一致的机制来控制复杂而又通常大不相同的低级硬件设备。

**操作系统**通过几个基本的抽象概念（进程、虚拟内存和文件）来实现上述连个功能。

如下图所示，文件是对设备的抽象表示，虚拟内存是对主存和磁盘IO设备的抽象表示，进程则是对处理器、主存和IO设备的抽象表示。

<div align = center>
<img src = "https://img-blog.csdnimg.cn/2019100610390692.png" width = "80%">
<div align = left>

### 1.7.1 进程

当程序在现代系统上运行时，操作系统会提供一种假象，就好像系统上只有这个程序在运行。程序看上去是独占地使用处理器、主存和IO设备。处理器看上去就像在不间断地一条接一条地执行程序中的指令，即该程序的代码和数据时系统内存中唯一的对象。

**进程**是操作系统对一个正在执行的程序的一种抽象。在一个系统上可以同时运行多个进程，而每个进程都好像在独占地使用硬件。

操作系统保持跟踪进程运行所需的所有状态信息。这种状态也就是**上下文**，包括许多信息，比如PC和寄存器文件的当前值，以及主存的内容。

在任何一个时刻，但处理器系统都只能执行一个进程的代码。当操作系统决定要报控制权从当前进程转移到某个新进程时，就会进程**上下文切换**，即保存当前进程的上下文、恢复新进程的上下文，然后将控制权传递到新进程。

### 1.7.2 线程

在现代系统中，一个进程实际上可以由多个称为**线程**的执行单元组成，每个线程都运行在进程的上下文中，并共享同样的代码和全局数据。

### 1.7.3 虚拟内存

**虚拟内存**是一个抽象概念，它为每个进程提供了一个假象，即每个进程都在独占地使用主存。每个进程看到的内存都是一致的，称为**虚拟地址空间**。

在Linux中，地址空间最上面的区域是保留给操作系统中的代码和数据的，这对所有的进程来说都是一样的。

地址空间的底部区域存放用户进程定义的代码和数据。

<div align = center>
<img src = "https://img-blog.csdnimg.cn/20191006110231171.png" width = "50%">
<div align = left>

 - **程序代码和数据**：对所有的进程来说，代码是从同一固定地址开始，紧接着是和C全局变量相对应的数据位置。代码和数据区是直接按照可执行文件目标文件的内容初始化的。
 - **堆**：代码和数据区后紧随着的是运行时堆。代码和数据区在进程一开始运行时就被指定了大小，与此不同，当调用像malloc和free这样的C标准函数时，堆可以在运行时动态地扩展和收缩。
 - **共享库**：在地址空间的中间部分是一块用来存放像C标准库和数学库这样的共享库的代码和数据的区域。
 - **栈**：位于用户虚拟地址空间顶部的是**用户栈**，编译器用它来实现函数调用。和堆一样，用户栈在程序执行期间可以动态地扩展和收缩。
 - **内核虚拟内存**：地址空间顶部的区域是为内核保留的。不允许应用程序读写这个区域的内容或者直接调用内核代码定义的函数。它们必须调用内核来执行这些操作。

### 1.7.4 文件

**文件**就是字节序列，每个IO设备，包括磁盘、键盘、显示器，甚至网络，都可以看成是文件。

系统中的所有输入输出都是通过使用一小组称为Unix I/O的系统函数调用读写文件来实现的。

## 1.8 系统之间利用网络通信

从一个单独的系统来看，网络可视为一个IO设备。当系统从主存复制一串字节到网络适配器时，数据流经过网络到达另一台机器，而不是比如说到达本地磁盘驱动器。相思地，系统可以读取从其他机器发送来的数据，并把数据复制到自己的主存。

## 重要主题

### 1.9.1 Amdahl定律

**主要思想**：当我们对系统的某个部分加速时，其对系统整体性能的影响取决于该部分的重要性和加速程度。

若系统执行某应用程序需要时间为`T_old`。假设系统某部分所需执行时间与该时间的比例为`α`，则该部分性能提升比例为`k`。即该部分初始所需时间为`αT_old`，现在所需时间为`(αT_old)/k`。因此，总的执行时间应为

`T_new = (1-α)T_old + (αT_old)/k = T_old[(1-α) + α/k]`

由此，可以计算加速比`S = T_old / T_new`为`S = 1 / [(1-α) + α/k]`

`Amdahl定律`一个有趣的情况是考虑`k`趋向于`∞`时的效果，`S_∞ = 1 / (1-α)`

### 1.9.2 并发和并行

**并发**指一个同事具有多个活动的系统；**并行**指的是用并发来使一个系统运行得更快。

**1. 线程级并发**

在以前，即使处理器必须在多个任务键切换，大多数实际的计算也都是由一个处理器来完成的，这种配置称为**单处理器系统**。

**多核处理器**是将多个CPU集成到一个集成电路芯片上。下图描述的是一个典型多核处理器的组织结构，其中微处理器芯片有4个CPU核，每个核都有自己的L1和L2告诉缓存，其中的L1高速缓存分为两个部分--一个保存最近取到的指令，另一个存放数据。这些核共享更高层次的高速缓存，以及到主存的接口。

